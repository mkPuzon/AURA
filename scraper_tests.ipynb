{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843f1c76",
   "metadata": {},
   "source": [
    "How to use Python arXiv API\n",
    "\n",
    "Last updated: Sep 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f47c816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "\n",
    "from utils import inspect_dictionary\n",
    "from scrapers import get_arxiv_records, get_keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed1bd52",
   "metadata": {},
   "source": [
    "The arXiv API can be queried used an https request. The base query is of the form:\n",
    "\n",
    "http://export.arxiv.org/api/query\n",
    "\n",
    "To find papers on a certain subject, you'll use `search_query=all:` parameter. The all: prefix allows searching across all fields (title, author, abstract, comment, journal reference, subject category, report number). Note that spaces are not allowed in URLs, so they should be encoded with + signs.\n",
    "\n",
    "To get the most recent papers, you need to sort by date. The `sortBy=submittedDate` option sorts by the date the article was first submitted. For the most recent papers, the sort order should be `sortOrder=descending`. For the most popular papers use `sortBy=relevance`. This uses Lucene's default relevance search which orders results based on an internally \"computed relevance\" score (the system's best estimation of how well each document matches the query; can't currently find algorithmic details).\n",
    "\n",
    "Example query to get the 2 most recent papers related to \"artificial intelligence\":\n",
    "\n",
    "http://export.arxiv.org/api/query?search_query=all:artificial+intelligence&sortBy=submittedDate&sortOrder=descending&max_results=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc69f252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-22 == UniPixel: Unified Object Referring and Segmentation for Pixel-Level\n",
      "  Visual Reasoning\n",
      "2025-09-22 == SEQR: Secure and Efficient QR-based LoRA Routing\n",
      "2025-09-22 == OnePiece: Bringing Context Engineering and Reasoning to Industrial\n",
      "  Cascade Ranking System\n",
      "2025-09-22 == Spiffy: Multiplying Diffusion LLM Acceleration via Lossless Speculative\n",
      "  Decoding\n",
      "2025-09-22 == Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning\n",
      "Starting download of 5 articles...\n",
      "arxiv-downloader http://arxiv.org/pdf/2509.18094v1 -d papers\n",
      "arxiv-downloader http://arxiv.org/pdf/2509.18093v1 -d papers\n",
      "arxiv-downloader http://arxiv.org/pdf/2509.18091v1 -d papers\n",
      "arxiv-downloader http://arxiv.org/pdf/2509.18085v1 -d papers\n",
      "arxiv-downloader http://arxiv.org/pdf/2509.18083v1 -d papers\n"
     ]
    }
   ],
   "source": [
    "records = get_arxiv_records(\"artificial intelligence\", sort_by=\"date\", max_results=5)\n",
    "\n",
    "for paper in records:\n",
    "    print(f\"{records[paper][\"date_submitted\"]} == {records[paper][\"title\"]}\")\n",
    "    # try:\n",
    "    #     keywords = get_keywords(abstract=records[paper][\"abstract\"])\n",
    "    #     time.sleep(3)\n",
    "    #     print(keywords)\n",
    "    #     records[paper][\"generated_keywords\"] = keywords\n",
    "    # except:\n",
    "    #     print(f\"[ServerError] for paper {paper}: \")\n",
    "    \n",
    "print(f\"Starting download of {len(records)} articles...\")\n",
    "\n",
    "\n",
    "for paper in records:\n",
    "    pdf_url = records[paper].get(\"pdf_url\")\n",
    "    title = records[paper].get(\"title\") \n",
    "    print(f\"arxiv-downloader {pdf_url} -d papers\")      \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb7b9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'arxiv-downloader' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! arxiv-downloader http://arxiv.org/pdf/2509.18094v1 -d ./papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e68b1",
   "metadata": {},
   "source": [
    "## Attempting to return specific papers\n",
    "Attention is all you need: https://arxiv.org/abs/1706.03762"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ba151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific query for Google's attention paper\n",
    "records = get_arxiv_records(\"Attention Is All You Need\", sort_by=\"popularity\", max_results=3)\n",
    "\n",
    "for paper in records:\n",
    "    try:\n",
    "        keywords = get_keywords(abstract=records[paper][\"abstract\"])\n",
    "        time.sleep(3)\n",
    "        print(keywords)\n",
    "        records[paper][\"generated_keywords\"] = keywords\n",
    "    except:\n",
    "        print(f\"[ServerError] for paper {paper}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5435d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specific query for Google's attention paper\n",
    "records_authors = get_arxiv_records(\"Ashish Vaswani, Noam Shazeer, Niki Parmar\", sort_by=\"popularity\", max_results=3)\n",
    "for paper in records_authors:\n",
    "    try:\n",
    "        keywords = get_keywords(abstract=records_authors[paper][\"abstract\"])\n",
    "        time.sleep(3)\n",
    "        print(keywords)\n",
    "        records_authors[paper][\"generated_keywords\"] = keywords\n",
    "    except:\n",
    "        print(f\"[ServerError] for paper {paper}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b99bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in records:\n",
    "    print(f\"======== {records[entry].get(\"title\")}\")\n",
    "    print(f\"        {records[entry].get(\"authors\")}\")\n",
    "    print(f\"        {records[entry].get(\"generated_keywords\")}\")\n",
    "print()\n",
    "print()\n",
    "for entry in records_authors:\n",
    "    print(f\"======== {records_authors[entry].get(\"title\")}\")\n",
    "    print(f\"        {records_authors[entry].get(\"authors\")}\")\n",
    "    print(f\"        {records_authors[entry].get(\"generated_keywords\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53db61c5",
   "metadata": {},
   "source": [
    "NOTE: Seems difficult to search for specific things; relevance metric is pretty opaque."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
